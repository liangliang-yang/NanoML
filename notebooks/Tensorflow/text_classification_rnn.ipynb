{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX4n9TsbGw-f"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:23.628261Z",
     "iopub.status.busy": "2021-04-02T02:09:23.627570Z",
     "iopub.status.idle": "2021-04-02T02:09:23.630030Z",
     "shell.execute_reply": "2021-04-02T02:09:23.629535Z"
    },
    "id": "0nbI5DtDGw-i"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TnJztDZGw-n"
   },
   "source": [
    "# Text classification with an RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfN3bMR5Gw-o"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/text_classification_rnn\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/text_classification_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/text_classification_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/text_classification_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUWearf0Gw-p"
   },
   "source": [
    "This text classification tutorial trains a [recurrent neural network](https://developers.google.com/machine-learning/glossary/#recurrent_neural_network) on the [IMDB large movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/) for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2VQo4bajwUU"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:23.639872Z",
     "iopub.status.busy": "2021-04-02T02:09:23.639086Z",
     "iopub.status.idle": "2021-04-02T02:09:31.002432Z",
     "shell.execute_reply": "2021-04-02T02:09:31.002907Z"
    },
    "id": "z682XYsrjkY9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rXHa-w9JZhb"
   },
   "source": [
    "Import `matplotlib` and create a helper function to plot graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:31.008708Z",
     "iopub.status.busy": "2021-04-02T02:09:31.007962Z",
     "iopub.status.idle": "2021-04-02T02:09:31.010407Z",
     "shell.execute_reply": "2021-04-02T02:09:31.009894Z"
    },
    "id": "Mp1Z7P9pYRSK"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRmMubr0jrE2"
   },
   "source": [
    "## Setup input pipeline\n",
    "\n",
    "\n",
    "The IMDB large movie review dataset is a *binary classification* datasetâ€”all the reviews have either a *positive* or *negative* sentiment.\n",
    "\n",
    "Download the dataset using [TFDS](https://www.tensorflow.org/datasets). See the [loading text tutorial](../load_data/text.ipynb) for details on how to load this sort of data manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:31.015539Z",
     "iopub.status.busy": "2021-04-02T02:09:31.014641Z",
     "iopub.status.idle": "2021-04-02T02:09:35.285259Z",
     "shell.execute_reply": "2021-04-02T02:09:35.285723Z"
    },
    "id": "SHRwRoP2nVHX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Lighterkey\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\u001b[0m\n",
      "\u001b[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\Lighterkey\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWA4c2ir7g6p"
   },
   "source": [
    "Initially this returns a dataset of (text, label pairs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:35.291165Z",
     "iopub.status.busy": "2021-04-02T02:09:35.290456Z",
     "iopub.status.idle": "2021-04-02T02:09:36.962371Z",
     "shell.execute_reply": "2021-04-02T02:09:36.962809Z"
    },
    "id": "vd4_BGKyurao"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
      "label:  0\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print('text: ', example.numpy())\n",
    "    print('label: ', label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2qVJzcEluH_"
   },
   "source": [
    "Next shuffle the data for training and create batches of these `(text, label)` pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:36.967304Z",
     "iopub.status.busy": "2021-04-02T02:09:36.966595Z",
     "iopub.status.idle": "2021-04-02T02:09:36.968463Z",
     "shell.execute_reply": "2021-04-02T02:09:36.968968Z"
    },
    "id": "dDsCaZCDYZgm"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:36.973854Z",
     "iopub.status.busy": "2021-04-02T02:09:36.973142Z",
     "iopub.status.idle": "2021-04-02T02:09:36.976945Z",
     "shell.execute_reply": "2021-04-02T02:09:36.977366Z"
    },
    "id": "VznrltNOnUc5"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:36.983038Z",
     "iopub.status.busy": "2021-04-02T02:09:36.981456Z",
     "iopub.status.idle": "2021-04-02T02:09:37.625796Z",
     "shell.execute_reply": "2021-04-02T02:09:37.626229Z"
    },
    "id": "jqkvdcFv41wC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [b\"Out of all the Princess stories Disney has put out there, Cinderella probably has the most enduring appeal. I can't really say why, but for some reason, generation after generation thrusts her to the top of their lists. As a little girl, I wanted nothing more than to be Cinderella with her glass slipper- it was my absolute favorite costume.<br /><br />Honestly, I don't think there is any story that more realizes the longings of the human heart than Cinderella. Who has never wanted to run away from the drudgeries of daily life and find someone who sees you as no one else ever had? The story is older than the English language and somehow it still rings true.<br /><br />As for the characters, if nothing else, Disney can make a wonderful villain. Lady Tremaine is evil to the T, in a wonderfully calculating, not overtly physical way. Her cutting tongue and eyes do the work for her- she doesn't need staffs of lightening to strike fear into your heart. The animal friends tend to grate, especially that idiotic Gus. I would have cheered had he met his fate in Lucifer's jaws. Cinderella herself was no pushover- making some justly catty remarks at times. However, she just lacked the drive to make her entirely sympathetic. Sure, she was nice and fed animals, but what was keeping her at that place? We never know. Even if she only became a maid in another house, at least she's be getting paid and have a shot at respect. It seems the only reason things work out in the end for Cindy is that everything sort of falls to place in her lap. She never works for her dreams that she sings so fondly of.<br /><br />Which brings me to the music, which is lovely, as ever. Ilene woods has a lovely, rich voice, probably my favorite of any Disney heroine. Some big standards originated here- A Dream is a Wish Your Heart Makes, So This is Love, Bibbidi Bobbidi Boo...<br /><br />Cinderella is a wonderful heartfelt story with a ton of musical highlights. While it is lacking in some character development, it does provide some classic villains and excellent voice work. If you are feeling sick at heart, pop it in- it'll warm you up and make you hum Mmm Mmm Good!<br /><br />Quote of the film:<br /><br />-Surprise! Surprise! -Duh duh duh- Happy Birthday!\"\n",
      " b\"Dark Wolf (Quick Review) Let's get right to it: This is a repugnant piece of rotting roadkill with cow sh*t on it. It's just an awful movie. It's an urban werewolf movie with some of the worst acting imaginable and a story as weak as any gangly nerd from an 80's high school drama film. What's worse is that poor Kane Hodder was duped into playing the gigantic evil werewolf. Kane f*cking Hodder. Someone's trying to ensure that playing Jason Voorhees is the height of his film career...<br /><br />Anyway, former Playmate Jaime Bergman is also in the movie and she eventually becomes a werewolf, too. It's kind of a crappy cop drama with the world's worst looking werewolf in it. But it does have moments of near-rampant nudity. But that's about all. Want to know more? Okay, the werewolf is generally an ugly-looking black blur zipping around the screen. And when we're privileged enough to actually see a transformation sequence, we're presented with something that resembles a full-motion video from a video game made during the early stages of the Playstation. The first Playstation. The CG animation is really that primitive. Only good for horror hardcore fanatics that want to see small moments of nudity surrounded by rampant visual vomit. 2/10<br /><br />www.ResidentHazard.com\"\n",
      " b\"As the summary says you just made the most ignorant comment i have ever heard on an RPG. You seriously thought they were gay? Are you retarded? If you went to go save your best friend and someone decides out of the goodness of his heart to help you then you are in a serious debt to that man. Lavitz was a good person and each time they helped each other it made them closer as friends. They weren't gay lovers like your bitching about. And to let you know the game is set in a medieval time period. Back then, women did just prepare meals while the men fought. Do you even know your history? Do you know how long it took for women to be accepted in the army in present day? This game contains a lot of realism even though your too damn slow obviously to catch it, and you really need to spit out some solid proof instead of ignorant assumptions based off your misguided act to interpret the story.\"]\n",
      "\n",
      "labels:  [1 0 0]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print('texts: ', example.numpy()[:3])\n",
    "    print()\n",
    "    print('labels: ', label.numpy()[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5eWCo88voPY"
   },
   "source": [
    "## Create the text encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFevcItw15P_"
   },
   "source": [
    "The raw text loaded by `tfds` needs to be processed before it can be used in a model. The simplest way to process text for training is using the `experimental.preprocessing.TextVectorization` layer. This layer has many capabilities, but this tutorial sticks to the default behavior.\n",
    "\n",
    "Create the layer, and pass the dataset's text to the layer's `.adapt` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:37.631574Z",
     "iopub.status.busy": "2021-04-02T02:09:37.630888Z",
     "iopub.status.idle": "2021-04-02T02:09:42.309624Z",
     "shell.execute_reply": "2021-04-02T02:09:42.309004Z"
    },
    "id": "uC25Lu1Yvuqy"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuQzVBbe3Ldu"
   },
   "source": [
    "The `.adapt` method sets the layer's vocabulary. Here are the first 20 tokens. After the padding and unknown tokens they're sorted by frequency: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:42.314885Z",
     "iopub.status.busy": "2021-04-02T02:09:42.314191Z",
     "iopub.status.idle": "2021-04-02T02:09:42.319494Z",
     "shell.execute_reply": "2021-04-02T02:09:42.319011Z"
    },
    "id": "tBoyjjWg0Ac9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
       "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjId5pua3jHQ"
   },
   "source": [
    "Once the vocabulary is set, the layer can encode text into indices. The tensors of indices are 0-padded to the longest sequence in the batch (unless you set a fixed `output_sequence_length`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:42.324048Z",
     "iopub.status.busy": "2021-04-02T02:09:42.323370Z",
     "iopub.status.idle": "2021-04-02T02:09:42.338515Z",
     "shell.execute_reply": "2021-04-02T02:09:42.338977Z"
    },
    "id": "RGc7C9WiwRWs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 46,   5,  32, ...,   0,   0,   0],\n",
       "       [455,   1,   1, ...,   0,   0,   0],\n",
       "       [ 15,   2,   1, ...,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5cjz0bS39IN"
   },
   "source": [
    "With the default settings, the process is not completely reversible. There are three main reasons for that:\n",
    "\n",
    "1. The default value for `preprocessing.TextVectorization`'s `standardize` argument is `\"lower_and_strip_punctuation\"`.\n",
    "2. The limited vocabulary size and lack of character-based fallback results in some unknown tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:42.343816Z",
     "iopub.status.busy": "2021-04-02T02:09:42.343136Z",
     "iopub.status.idle": "2021-04-02T02:09:42.349183Z",
     "shell.execute_reply": "2021-04-02T02:09:42.348646Z"
    },
    "id": "N_tD0QY5wXaK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b\"Out of all the Princess stories Disney has put out there, Cinderella probably has the most enduring appeal. I can't really say why, but for some reason, generation after generation thrusts her to the top of their lists. As a little girl, I wanted nothing more than to be Cinderella with her glass slipper- it was my absolute favorite costume.<br /><br />Honestly, I don't think there is any story that more realizes the longings of the human heart than Cinderella. Who has never wanted to run away from the drudgeries of daily life and find someone who sees you as no one else ever had? The story is older than the English language and somehow it still rings true.<br /><br />As for the characters, if nothing else, Disney can make a wonderful villain. Lady Tremaine is evil to the T, in a wonderfully calculating, not overtly physical way. Her cutting tongue and eyes do the work for her- she doesn't need staffs of lightening to strike fear into your heart. The animal friends tend to grate, especially that idiotic Gus. I would have cheered had he met his fate in Lucifer's jaws. Cinderella herself was no pushover- making some justly catty remarks at times. However, she just lacked the drive to make her entirely sympathetic. Sure, she was nice and fed animals, but what was keeping her at that place? We never know. Even if she only became a maid in another house, at least she's be getting paid and have a shot at respect. It seems the only reason things work out in the end for Cindy is that everything sort of falls to place in her lap. She never works for her dreams that she sings so fondly of.<br /><br />Which brings me to the music, which is lovely, as ever. Ilene woods has a lovely, rich voice, probably my favorite of any Disney heroine. Some big standards originated here- A Dream is a Wish Your Heart Makes, So This is Love, Bibbidi Bobbidi Boo...<br /><br />Cinderella is a wonderful heartfelt story with a ton of musical highlights. While it is lacking in some character development, it does provide some classic villains and excellent voice work. If you are feeling sick at heart, pop it in- it'll warm you up and make you hum Mmm Mmm Good!<br /><br />Quote of the film:<br /><br />-Surprise! Surprise! -Duh duh duh- Happy Birthday!\"\n",
      "Round-trip:  out of all the [UNK] stories disney has put out there [UNK] probably has the most [UNK] [UNK] i cant really say why but for some reason [UNK] after [UNK] [UNK] her to the top of their [UNK] as a little girl i wanted nothing more than to be [UNK] with her [UNK] [UNK] it was my [UNK] favorite [UNK] br [UNK] i dont think there is any story that more [UNK] the [UNK] of the human heart than [UNK] who has never wanted to run away from the [UNK] of [UNK] life and find someone who [UNK] you as no one else ever had the story is older than the english [UNK] and somehow it still [UNK] [UNK] br as for the characters if nothing else disney can make a wonderful [UNK] lady [UNK] is evil to the [UNK] in a [UNK] [UNK] not [UNK] [UNK] way her [UNK] [UNK] and eyes do the work for her she doesnt need [UNK] of [UNK] to [UNK] [UNK] into your heart the [UNK] friends [UNK] to [UNK] especially that [UNK] [UNK] i would have [UNK] had he [UNK] his [UNK] in [UNK] [UNK] [UNK] herself was no [UNK] making some [UNK] [UNK] [UNK] at times however she just [UNK] the [UNK] to make her [UNK] [UNK] sure she was nice and [UNK] [UNK] but what was [UNK] her at that place we never know even if she only became a [UNK] in another house at least shes be getting [UNK] and have a shot at [UNK] it seems the only reason things work out in the end for [UNK] is that everything sort of falls to place in her [UNK] she never works for her [UNK] that she [UNK] so [UNK] [UNK] br which brings me to the music which is [UNK] as ever [UNK] [UNK] has a [UNK] [UNK] voice probably my favorite of any disney [UNK] some big [UNK] [UNK] here a dream is a wish your heart makes so this is love [UNK] [UNK] [UNK] br [UNK] is a wonderful [UNK] story with a [UNK] of musical [UNK] while it is [UNK] in some character development it does [UNK] some classic [UNK] and excellent voice work if you are feeling [UNK] at heart [UNK] it in [UNK] [UNK] you up and make you [UNK] [UNK] [UNK] [UNK] br [UNK] of the filmbr br surprise surprise [UNK] [UNK] [UNK] happy [UNK]                                                                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "Original:  b\"Dark Wolf (Quick Review) Let's get right to it: This is a repugnant piece of rotting roadkill with cow sh*t on it. It's just an awful movie. It's an urban werewolf movie with some of the worst acting imaginable and a story as weak as any gangly nerd from an 80's high school drama film. What's worse is that poor Kane Hodder was duped into playing the gigantic evil werewolf. Kane f*cking Hodder. Someone's trying to ensure that playing Jason Voorhees is the height of his film career...<br /><br />Anyway, former Playmate Jaime Bergman is also in the movie and she eventually becomes a werewolf, too. It's kind of a crappy cop drama with the world's worst looking werewolf in it. But it does have moments of near-rampant nudity. But that's about all. Want to know more? Okay, the werewolf is generally an ugly-looking black blur zipping around the screen. And when we're privileged enough to actually see a transformation sequence, we're presented with something that resembles a full-motion video from a video game made during the early stages of the Playstation. The first Playstation. The CG animation is really that primitive. Only good for horror hardcore fanatics that want to see small moments of nudity surrounded by rampant visual vomit. 2/10<br /><br />www.ResidentHazard.com\"\n",
      "Round-trip:  dark [UNK] [UNK] review lets get right to it this is a [UNK] piece of [UNK] [UNK] with [UNK] [UNK] on it its just an awful movie its an [UNK] [UNK] movie with some of the worst acting [UNK] and a story as weak as any [UNK] [UNK] from an 80s high school drama film whats worse is that poor [UNK] [UNK] was [UNK] into playing the [UNK] evil [UNK] [UNK] [UNK] [UNK] [UNK] trying to [UNK] that playing [UNK] [UNK] is the [UNK] of his film [UNK] br anyway [UNK] [UNK] [UNK] [UNK] is also in the movie and she eventually becomes a [UNK] too its kind of a [UNK] [UNK] drama with the [UNK] worst looking [UNK] in it but it does have moments of [UNK] [UNK] but thats about all want to know more okay the [UNK] is [UNK] an [UNK] black [UNK] [UNK] around the screen and when were [UNK] enough to actually see a [UNK] sequence were [UNK] with something that [UNK] a [UNK] video from a video game made during the early [UNK] of the [UNK] the first [UNK] the [UNK] animation is really that [UNK] only good for horror [UNK] [UNK] that want to see small moments of [UNK] [UNK] by [UNK] [UNK] [UNK] [UNK] br [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "\n",
      "Original:  b\"As the summary says you just made the most ignorant comment i have ever heard on an RPG. You seriously thought they were gay? Are you retarded? If you went to go save your best friend and someone decides out of the goodness of his heart to help you then you are in a serious debt to that man. Lavitz was a good person and each time they helped each other it made them closer as friends. They weren't gay lovers like your bitching about. And to let you know the game is set in a medieval time period. Back then, women did just prepare meals while the men fought. Do you even know your history? Do you know how long it took for women to be accepted in the army in present day? This game contains a lot of realism even though your too damn slow obviously to catch it, and you really need to spit out some solid proof instead of ignorant assumptions based off your misguided act to interpret the story.\"\n",
      "Round-trip:  as the [UNK] says you just made the most [UNK] comment i have ever heard on an [UNK] you seriously thought they were [UNK] are you [UNK] if you went to go save your best friend and someone [UNK] out of the [UNK] of his heart to help you then you are in a serious [UNK] to that man [UNK] was a good person and each time they [UNK] each other it made them [UNK] as friends they [UNK] [UNK] [UNK] like your [UNK] about and to let you know the game is set in a [UNK] time period back then women did just [UNK] [UNK] while the men [UNK] do you even know your history do you know how long it took for women to be [UNK] in the [UNK] in present day this game [UNK] a lot of [UNK] even though your too [UNK] slow obviously to [UNK] it and you really need to [UNK] out some [UNK] [UNK] instead of [UNK] [UNK] based off your [UNK] act to [UNK] the story                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "    print(\"Original: \", example[n].numpy())\n",
    "    print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjUqGVBxGw-t"
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7zsmInBOCPO"
   },
   "source": [
    "![A drawing of the information flow in the model](images/bidirectional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgs6nnSTGw-t"
   },
   "source": [
    "Above is a diagram of the model. \n",
    "\n",
    "1. This model can be build as a `tf.keras.Sequential`.\n",
    "\n",
    "2. The first layer is the `encoder`, which converts the text to a sequence of token indices.\n",
    "\n",
    "3. After the encoder is an embedding layer. An embedding layer stores one vector per word. When called, it converts the sequences of word indices to sequences of vectors. These vectors are trainable. After training (on enough data), words with similar meanings often have similar vectors.\n",
    "\n",
    "  This index-lookup is much more efficient than the equivalent operation of passing a one-hot encoded vector through a `tf.keras.layers.Dense` layer.\n",
    "\n",
    "4. A recurrent neural network (RNN) processes sequence input by iterating through the elements. RNNs pass the outputs from one timestep to their input on the next timestep.\n",
    "\n",
    "  The `tf.keras.layers.Bidirectional` wrapper can also be used with an RNN layer. This propagates the input forward and backwards through the RNN layer and then concatenates the final output. \n",
    "\n",
    "  * The main advantage of a bidirectional RNN is that the signal from the beginning of the input doesn't need to be processed all the way through every timestep to affect the output.  \n",
    "\n",
    "  * The main disadvantage of a bidirectional RNN is that you can't efficiently stream predictions as words are being added to the end.\n",
    "\n",
    "5. After the RNN has converted the sequence to a single vector the two `layers.Dense` do some final processing, and convert from this vector representation to a single logit as the classification output. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4fodCI7soQi"
   },
   "source": [
    "The code to implement this is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:42.355201Z",
     "iopub.status.busy": "2021-04-02T02:09:42.354514Z",
     "iopub.status.idle": "2021-04-02T02:09:42.395664Z",
     "shell.execute_reply": "2021-04-02T02:09:42.396129Z"
    },
    "id": "LwfoBkmRYcP3"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIGmIGkkouUb"
   },
   "source": [
    "Please note that Keras sequential model is used here since all the layers in the model only have single input and produce single output. In case you want to use stateful RNN layer, you might want to build your model with Keras functional API or model subclassing so that you can retrieve and reuse the RNN layer states. Please check [Keras RNN guide](https://www.tensorflow.org/guide/keras/rnn#rnn_state_reuse) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kF-PsCk1LwjY"
   },
   "source": [
    "The embedding layer [uses masking](https://www.tensorflow.org/guide/keras/masking_and_padding) to handle the varying sequence-lengths. All the layers after the `Embedding` support masking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:42.401415Z",
     "iopub.status.busy": "2021-04-02T02:09:42.400718Z",
     "iopub.status.idle": "2021-04-02T02:09:42.402987Z",
     "shell.execute_reply": "2021-04-02T02:09:42.403427Z"
    },
    "id": "87a8-CwfKebw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([layer.supports_masking for layer in model.layers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlS0iaUIWLpI"
   },
   "source": [
    "To confirm that this works as expected, evaluate a sentence twice. First, alone so there's no padding to mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:42.409030Z",
     "iopub.status.busy": "2021-04-02T02:09:42.408347Z",
     "iopub.status.idle": "2021-04-02T02:09:49.830035Z",
     "shell.execute_reply": "2021-04-02T02:09:49.829468Z"
    },
    "id": "O41gw3KfWHus"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00261081]\n"
     ]
    }
   ],
   "source": [
    "# predict on a sample text without padding.\n",
    "\n",
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0VQmGnEWcuz"
   },
   "source": [
    "Now, evaluate it again in a batch with a longer sentence. The result should be identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:49.836464Z",
     "iopub.status.busy": "2021-04-02T02:09:49.835731Z",
     "iopub.status.idle": "2021-04-02T02:09:50.008313Z",
     "shell.execute_reply": "2021-04-02T02:09:50.008773Z"
    },
    "id": "UIgpuTeFNDzq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00261081]\n"
     ]
    }
   ],
   "source": [
    "# predict on a sample text with padding\n",
    "\n",
    "padding = \"the \" * 2000\n",
    "predictions = model.predict(np.array([sample_text, padding]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRI776ZcH3Tf"
   },
   "source": [
    "Compile the Keras model to configure the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:50.025090Z",
     "iopub.status.busy": "2021-04-02T02:09:50.024309Z",
     "iopub.status.idle": "2021-04-02T02:09:50.037046Z",
     "shell.execute_reply": "2021-04-02T02:09:50.037452Z"
    },
    "id": "kj2xei41YZjC"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIwH3nto596k"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:09:50.042548Z",
     "iopub.status.busy": "2021-04-02T02:09:50.041835Z",
     "iopub.status.idle": "2021-04-02T02:15:49.160067Z",
     "shell.execute_reply": "2021-04-02T02:15:49.160483Z"
    },
    "id": "hw86wWS4YgR2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 779s 2s/step - loss: 0.4117 - accuracy: 0.8180 - val_loss: 0.3821 - val_accuracy: 0.8339\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 823s 2s/step - loss: 0.3498 - accuracy: 0.8480 - val_loss: 0.3477 - val_accuracy: 0.8495\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 830s 2s/step - loss: 0.3267 - accuracy: 0.8599 - val_loss: 0.3356 - val_accuracy: 0.8490\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 806s 2s/step - loss: 0.3126 - accuracy: 0.8657 - val_loss: 0.3279 - val_accuracy: 0.8578\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 783s 2s/step - loss: 0.3068 - accuracy: 0.8686 - val_loss: 0.3240 - val_accuracy: 0.8583\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 790s 2s/step - loss: 0.3053 - accuracy: 0.8699 - val_loss: 0.3278 - val_accuracy: 0.8495\n",
      "Epoch 7/10\n",
      "215/391 [===============>..............] - ETA: 5:53 - loss: 0.3040 - accuracy: 0.8713"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:15:49.165492Z",
     "iopub.status.busy": "2021-04-02T02:15:49.164837Z",
     "iopub.status.idle": "2021-04-02T02:16:05.725623Z",
     "shell.execute_reply": "2021-04-02T02:16:05.726116Z"
    },
    "id": "BaNbXi43YgUT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88/391 [=====>........................] - ETA: 1:14 - loss: 0.3135 - accuracy: 0.8567"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d2a5468effeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test Loss:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test Accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1387\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:16:05.748661Z",
     "iopub.status.busy": "2021-04-02T02:16:05.733404Z",
     "iopub.status.idle": "2021-04-02T02:16:06.021648Z",
     "shell.execute_reply": "2021-04-02T02:16:06.022109Z"
    },
    "id": "OZmwt_mzaQJk"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwSE_386uhxD"
   },
   "source": [
    "Run a prediction on a new sentence:\n",
    "\n",
    "If the prediction is >= 0.0, it is positive else it is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:16:06.026733Z",
     "iopub.status.busy": "2021-04-02T02:16:06.026090Z",
     "iopub.status.idle": "2021-04-02T02:16:07.969281Z",
     "shell.execute_reply": "2021-04-02T02:16:07.968592Z"
    },
    "id": "ZXgfQSgRW6zU"
   },
   "outputs": [],
   "source": [
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "predictions = model.predict(np.array([sample_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7g1evcaRpTKm"
   },
   "source": [
    "## Stack two or more LSTM layers\n",
    "\n",
    "Keras recurrent layers have two available modes that are controlled by the `return_sequences` constructor argument:\n",
    "\n",
    "* If `False` it returns only the last output for each input sequence (a 2D tensor of shape (batch_size, output_features)). This is the default, used in the previous model.\n",
    "\n",
    "* If `True` the full sequences of successive outputs for each timestep is returned (a 3D tensor of shape `(batch_size, timesteps, output_features)`).\n",
    "\n",
    "Here is what the flow of information looks like with `return_sequences=True`:\n",
    "\n",
    "![layered_bidirectional](images/layered_bidirectional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbSClCrG1z8l"
   },
   "source": [
    "The interesting thing about using an `RNN` with `return_sequences=True` is that the output still has 3-axes, like the input, so it can be passed to another RNN layer, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:16:07.977375Z",
     "iopub.status.busy": "2021-04-02T02:16:07.976671Z",
     "iopub.status.idle": "2021-04-02T02:16:08.010571Z",
     "shell.execute_reply": "2021-04-02T02:16:08.010009Z"
    },
    "id": "jo1jjO3vn0jo"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:16:08.020237Z",
     "iopub.status.busy": "2021-04-02T02:16:08.019590Z",
     "iopub.status.idle": "2021-04-02T02:16:08.023761Z",
     "shell.execute_reply": "2021-04-02T02:16:08.023268Z"
    },
    "id": "hEPV5jVGp-is"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:16:08.028061Z",
     "iopub.status.busy": "2021-04-02T02:16:08.027398Z",
     "iopub.status.idle": "2021-04-02T02:26:14.849595Z",
     "shell.execute_reply": "2021-04-02T02:26:14.850059Z"
    },
    "id": "LeSE-YjdqAeN"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:26:14.855139Z",
     "iopub.status.busy": "2021-04-02T02:26:14.854502Z",
     "iopub.status.idle": "2021-04-02T02:26:41.313254Z",
     "shell.execute_reply": "2021-04-02T02:26:41.313739Z"
    },
    "id": "_LdwilM1qPM3"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:26:41.318315Z",
     "iopub.status.busy": "2021-04-02T02:26:41.317631Z",
     "iopub.status.idle": "2021-04-02T02:26:45.083609Z",
     "shell.execute_reply": "2021-04-02T02:26:45.083031Z"
    },
    "id": "ykUKnAoqbycW"
   },
   "outputs": [],
   "source": [
    "# predict on a sample text without padding.\n",
    "\n",
    "sample_text = ('The movie was not good. The animation and the graphics '\n",
    "               'were terrible. I would not recommend this movie.')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:26:45.102461Z",
     "iopub.status.busy": "2021-04-02T02:26:45.100958Z",
     "iopub.status.idle": "2021-04-02T02:26:45.354347Z",
     "shell.execute_reply": "2021-04-02T02:26:45.354795Z"
    },
    "id": "_YYub0EDtwCu"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xvpE3BaGw_V"
   },
   "source": [
    "Check out other existing recurrent layers such as [GRU layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU).\n",
    "\n",
    "If you're interestied in building custom RNNs, see the [Keras RNN Guide](https://www.tensorflow.org/guide/keras/rnn).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification_rnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python nanoml",
   "language": "python",
   "name": "nanoml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
