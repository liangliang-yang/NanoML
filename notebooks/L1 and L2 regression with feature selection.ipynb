{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "* https://blog.datadive.net/selecting-good-features-part-ii-linear-models-and-regularization/ 【主要是这个】\n",
    "* https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "* https://medium.com/@23.sargam/lasso-regression-for-feature-selection-8ac2287e25fa 【这个解释了原理为什么不会是零】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model: 0.984 * X0 + 1.995 * X1 + -0.041 * X2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    " \n",
    "np.random.seed(0)\n",
    "size = 5000\n",
    " \n",
    "#A dataset with 3 features\n",
    "X = np.random.normal(0, 1, (size, 3))\n",
    "#Y = X0 + 2*X1 + noise\n",
    "Y = X[:,0] + 2*X[:,1] + np.random.normal(0, 2, size)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, Y)\n",
    " \n",
    "#A helper method for pretty-printing linear models\n",
    "def pretty_print_linear(coefs, names = None, sort = False):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name)\n",
    "                                   for coef, name in lst)\n",
    " \n",
    "print(\"Linear model:\", pretty_print_linear(lr.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 regularization / Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A helper method for pretty-printing linear models\n",
    "def pretty_print_linear(coefs, names = None, sort = False):\n",
    "    if names is None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name)\n",
    "                                   for coef, name in lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model:  -3.705 * LSTAT + 2.993 * RM + -1.756 * PTRATIO + -1.081 * DIS + -0.699 * NOX + 0.628 * B + 0.54 * CHAS + -0.242 * CRIM + 0.082 * ZN + -0.0 * INDUS + -0.0 * AGE + 0.0 * RAD + -0.0 * TAX\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(boston[\"data\"])\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "  \n",
    "lasso = Lasso(alpha=.3)\n",
    "lasso.fit(X, Y)\n",
    "  \n",
    "print(\"Lasso model: \", pretty_print_linear(lasso.coef_, names, sort = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a number of features have coefficient 0. If we increase α further, the solution would be sparser and sparser, i.e. more and more features would have 0 as coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 regularization / Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 0\n",
      "Linear model: 0.728 * X0 + 2.309 * X1 + -0.082 * X2\n",
      "Ridge model: 0.938 * X0 + 1.059 * X1 + 0.877 * X2\n",
      " \n",
      "Random seed 1\n",
      "Linear model: 1.152 * X0 + 2.366 * X1 + -0.599 * X2\n",
      "Ridge model: 0.984 * X0 + 1.068 * X1 + 0.759 * X2\n",
      " \n",
      "Random seed 2\n",
      "Linear model: 0.697 * X0 + 0.322 * X1 + 2.086 * X2\n",
      "Ridge model: 0.972 * X0 + 0.943 * X1 + 1.085 * X2\n",
      " \n",
      "Random seed 3\n",
      "Linear model: 0.287 * X0 + 1.254 * X1 + 1.491 * X2\n",
      "Ridge model: 0.919 * X0 + 1.005 * X1 + 1.033 * X2\n",
      " \n",
      "Random seed 4\n",
      "Linear model: 0.187 * X0 + 0.772 * X1 + 2.189 * X2\n",
      "Ridge model: 0.964 * X0 + 0.982 * X1 + 1.098 * X2\n",
      " \n",
      "Random seed 5\n",
      "Linear model: -1.291 * X0 + 1.591 * X1 + 2.747 * X2\n",
      "Ridge model: 0.758 * X0 + 1.011 * X1 + 1.139 * X2\n",
      " \n",
      "Random seed 6\n",
      "Linear model: 1.199 * X0 + -0.031 * X1 + 1.915 * X2\n",
      "Ridge model: 1.016 * X0 + 0.89 * X1 + 1.091 * X2\n",
      " \n",
      "Random seed 7\n",
      "Linear model: 1.474 * X0 + 1.762 * X1 + -0.151 * X2\n",
      "Ridge model: 1.018 * X0 + 1.039 * X1 + 0.901 * X2\n",
      " \n",
      "Random seed 8\n",
      "Linear model: 0.084 * X0 + 1.88 * X1 + 1.107 * X2\n",
      "Ridge model: 0.907 * X0 + 1.071 * X1 + 1.008 * X2\n",
      " \n",
      "Random seed 9\n",
      "Linear model: 0.714 * X0 + 0.776 * X1 + 1.364 * X2\n",
      "Ridge model: 0.896 * X0 + 0.903 * X1 + 0.98 * X2\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "size = 100\n",
    " \n",
    "#We run the method 10 times with different random seeds\n",
    "for i in range(10):\n",
    "    print(\"Random seed %s\" % i)\n",
    "    np.random.seed(seed=i)\n",
    "    X_seed = np.random.normal(0, 1, size)\n",
    "    X1 = X_seed + np.random.normal(0, .1, size)\n",
    "    X2 = X_seed + np.random.normal(0, .1, size)\n",
    "    X3 = X_seed + np.random.normal(0, .1, size)\n",
    "    Y = X1 + X2 + X3 + np.random.normal(0, 1, size)\n",
    "    X = np.array([X1, X2, X3]).T\n",
    " \n",
    " \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X,Y)\n",
    "    print(\"Linear model:\", pretty_print_linear(lr.coef_))\n",
    " \n",
    "    ridge = Ridge(alpha=10)\n",
    "    ridge.fit(X,Y)\n",
    "    print(\"Ridge model:\", pretty_print_linear(ridge.coef_))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
